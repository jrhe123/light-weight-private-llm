{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea125886",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agent initialized with model: qwen3:latest\n",
      "Try asking: 'What is 12345 multiplied by 6789?' or 'What's the weather in Beijing?'\n",
      "--------------------------------------------------\n",
      "User: Calculate (123 + 234) * 45\n",
      "Agent decided to call tool(s)...\n",
      "  > Executing: calculate({'expression': '(123 + 234) * 45'})\n",
      "Agent: The result of the calculation is $\\boxed{16065}$.\n",
      "\n",
      "User: What is the weather like in Beijing right now?\n",
      "Agent decided to call tool(s)...\n",
      "  > Executing: get_current_weather({'location': 'Beijing', 'unit': 'celsius'})\n",
      "Agent: The current weather in Beijing is **22¬∞C** with a forecast of **sunny** and **windy**. Enjoy the pleasant conditions! üåûüå¨Ô∏è\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import math\n",
    "from openai import OpenAI\n",
    "\n",
    "os.environ[\"NO_PROXY\"] = \"192.168.1.10,localhost,127.0.0.1\"\n",
    "\n",
    "# 1. Configuration\n",
    "# Assuming Ollama is running locally on default port\n",
    "client = OpenAI(\n",
    "    base_url='http://192.168.1.10:11434/v1',\n",
    "    api_key='ollama',  # required, but unused by Ollama\n",
    ")\n",
    "MODEL_NAME = \"qwen3:latest\" # User asked for Qwen3, but it might not be available yet. Adjust this if you have a specific tag like 'qwen3'.\n",
    "\n",
    "# 2. Define the Functions (The \"Tools\")\n",
    "\n",
    "def calculate(expression):\n",
    "    \"\"\"\n",
    "    Evaluates a basic mathematical expression.\n",
    "    Safe for + - * / operations.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Using eval for simplicity in this demo, but strictly limiting context is better for production\n",
    "        allowed_names = {\"math\": math, \"abs\": abs, \"round\": round}\n",
    "        code = compile(expression, \"<string>\", \"eval\")\n",
    "        for name in code.co_names:\n",
    "            if name not in allowed_names:\n",
    "                raise NameError(f\"Use of {name} is not allowed\")\n",
    "        result = eval(code, {\"__builtins__\": {}}, allowed_names)\n",
    "        return json.dumps({\"result\": result})\n",
    "    except Exception as e:\n",
    "        return json.dumps({\"error\": str(e)})\n",
    "\n",
    "def get_current_weather(location, unit=\"celsius\"):\n",
    "    \"\"\"\n",
    "    Get the current weather in a given location.\n",
    "    (Mock implementation)\n",
    "    \"\"\"\n",
    "    # In a real app, you would call an API like OpenWeatherMap here\n",
    "    # Mocking data for demonstration\n",
    "    weather_info = {\n",
    "        \"location\": location,\n",
    "        \"temperature\": \"22\",\n",
    "        \"unit\": unit,\n",
    "        \"forecast\": [\"sunny\", \"windy\"]\n",
    "    }\n",
    "    return json.dumps(weather_info)\n",
    "\n",
    "# 3. Define Tool Schemas for the LLM\n",
    "tools = [\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"calculate\",\n",
    "            \"description\": \"Calculate the result of a mathematical expression. Useful for precise math.\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"expression\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"The mathematical expression to evaluate (e.g., '2 + 2', '3.5 * 40').\",\n",
    "                    },\n",
    "                },\n",
    "                \"required\": [\"expression\"],\n",
    "            },\n",
    "        },\n",
    "    },\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"get_current_weather\",\n",
    "            \"description\": \"Get the current weather for a specific location.\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"location\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"The city and state, e.g. San Francisco, CA\",\n",
    "                    },\n",
    "                    \"unit\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"enum\": [\"celsius\", \"fahrenheit\"],\n",
    "                    },\n",
    "                },\n",
    "                \"required\": [\"location\"],\n",
    "            },\n",
    "        },\n",
    "    },\n",
    "]\n",
    "\n",
    "# Map function names to actual Python functions\n",
    "available_functions = {\n",
    "    \"calculate\": calculate,\n",
    "    \"get_current_weather\": get_current_weather,\n",
    "}\n",
    "\n",
    "# 4. The Agent Logic\n",
    "\n",
    "def run_agent(user_prompt):\n",
    "    messages = [{\"role\": \"user\", \"content\": user_prompt}]\n",
    "    \n",
    "    print(f\"User: {user_prompt}\")\n",
    "    \n",
    "    # First call to LLM: See if it wants to use tools\n",
    "    response = client.chat.completions.create(\n",
    "        model=MODEL_NAME,\n",
    "        messages=messages,\n",
    "        tools=tools, # Ê®°ÂûãÂèØ‰ª•‰ΩøÁî®ÁöÑ‚ÄúÂ∑•ÂÖ∑ÁÆ±‚Äù„ÄÇJSON Schema Ê†ºÂºèÔºåÂëäËØâÊ®°ÂûãÔºö‚ÄúÂ¶ÇÊûú‰Ω†ËßâÂæóÊúâÂøÖË¶ÅÔºå‰Ω†ÂèØ‰ª•Ë∞ÉÁî®Ëøô‰∫õÂáΩÊï∞‚Äù„ÄÇ\n",
    "                     # Ê®°Âûã‰∏ç‰ºöÁõ¥Êé•ËøêË°åËøô‰∫õÂáΩÊï∞ÔºåËÄåÊòØËøîÂõû‰∏Ä‰∏™‚ÄúË∞ÉÁî®ËØ∑Ê±Ç‚ÄùÔºåÁî±‰Ω†ÁöÑ Python ‰ª£Á†ÅÂéªÊâßË°å„ÄÇ\n",
    "        tool_choice=\"auto\", # \"auto\"ÔºàÈªòËÆ§ÔºâÔºöÊ®°ÂûãËá™Âä®ÂÜ≥ÂÆö„ÄÇÂÆÉ‰ºöÊ†πÊçÆÁî®Êà∑ÁöÑÊÑèÂõæÔºåËá™‰∏ªÂà§Êñ≠ÊòØÁõ¥Êé•ÂõûÂ§çÊñáÂ≠óÔºåËøòÊòØË∞ÉÁî® tools ‰∏≠ÁöÑÊüê‰∏™ÂáΩÊï∞„ÄÇ\n",
    "    )\n",
    "    \n",
    "    response_message = response.choices[0].message\n",
    "    #print(f\"response_message:{response_message}\")\n",
    "    tool_calls = response_message.tool_calls\n",
    "    \n",
    "    # If the model decided to call functions\n",
    "    if tool_calls:\n",
    "        print(f\"Agent decided to call tool(s)...\")\n",
    "        messages.append(response_message)  # extend conversation with assistant's reply\n",
    "        \n",
    "        for tool_call in tool_calls:\n",
    "            function_name = tool_call.function.name\n",
    "            function_to_call = available_functions.get(function_name)\n",
    "            function_args = json.loads(tool_call.function.arguments)\n",
    "            \n",
    "            if function_to_call:\n",
    "                print(f\"  > Executing: {function_name}({function_args})\")\n",
    "                function_response = function_to_call(**function_args)\n",
    "                \n",
    "                messages.append(\n",
    "                    {\n",
    "                        \"tool_call_id\": tool_call.id,\n",
    "                        \"role\": \"tool\",\n",
    "                        \"name\": function_name,\n",
    "                        \"content\": function_response,\n",
    "                    }\n",
    "                )\n",
    "        \n",
    "        # Second call to LLM: Get the final answer based on tool outputs\n",
    "        final_response = client.chat.completions.create(\n",
    "            model=MODEL_NAME,\n",
    "            messages=messages,\n",
    "        )\n",
    "        return final_response.choices[0].message.content\n",
    "    else:\n",
    "        # No tools needed\n",
    "        return response_message.content\n",
    "\n",
    "# 5. Run interactively\n",
    "if __name__ == \"__main__\":\n",
    "    print(f\"Agent initialized with model: {MODEL_NAME}\")\n",
    "    print(\"Try asking: 'What is 12345 multiplied by 6789?' or 'What's the weather in Beijing?'\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    # Example 1: Math\n",
    "    q1 = \"Calculate (123 + 234) * 45\"\n",
    "    ans1 = run_agent(q1)\n",
    "    print(f\"Agent: {ans1}\\n\")\n",
    "\n",
    "    # Example 2: Weather\n",
    "    q2 = \"What is the weather like in Beijing right now?\"\n",
    "    ans2 = run_agent(q2)\n",
    "    print(f\"Agent: {ans2}\\n\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LLMs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
