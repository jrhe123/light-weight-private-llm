{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4ccc1cbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'instruction': 'Evaluate the following phrase by transforming it into the spelling given.', 'input': 'freind --> friend', 'output': 'The spelling of the given phrase \"freind\" is incorrect, the correct spelling is \"friend\".'}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "with open(\"instruction-data.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "print(data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8ff58832",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below is an instruction that describe a task.Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Evaluate the following phrase by transforming it into the spelling given.\n",
      "\n",
      "### Input:\n",
      "freind --> friend\n",
      "\n",
      "### Response:\n",
      "The spelling of the given phrase \"freind\" is incorrect, the correct spelling is \"friend\".\n"
     ]
    }
   ],
   "source": [
    "def format_input(item):\n",
    "    instruction_text = (\n",
    "        f\"Below is an instruction that describe a task.\"\n",
    "        f\"Write a response that appropriately completes the request.\"\n",
    "        f\"\\n\\n### Instruction:\\n{item['instruction']}\"\n",
    "    )\n",
    "\n",
    "    input_text = f\"\\n\\n### Input:\\n{item['input']}\" if item['input'] else \"\"\n",
    "    return instruction_text + input_text\n",
    "\n",
    "myinput = format_input(data[0])\n",
    "response = f\"\\n\\n### Response:\\n{data[0]['output']}\"\n",
    "\n",
    "print(myinput + response)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "955c8ba2",
   "metadata": {},
   "source": [
    "### Split Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7143e9d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train set length:  880\n",
      "val set length:  110\n",
      "test set length:  110\n"
     ]
    }
   ],
   "source": [
    "# 8:1:1 (dataset split)\n",
    "train_part = int(len(data) * 0.8)\n",
    "val_part = int(len(data) * 0.1)\n",
    "test_part = len(data) - train_part - val_part\n",
    "\n",
    "train_data = data[:train_part]\n",
    "val_data = data[train_part:train_part + val_part]\n",
    "test_data = data[train_part + val_part:]\n",
    "\n",
    "print(\"train set length: \", len(train_data))\n",
    "print(\"val set length: \", len(val_data))\n",
    "print(\"test set length: \", len(test_data))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ce56dc9",
   "metadata": {},
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "250f5f8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class InstructionDataset(Dataset):\n",
    "    def __init__(self, data, tokenizer):\n",
    "        self.data = data\n",
    "        self.samples = []\n",
    "\n",
    "        for i in data:\n",
    "            input = format_input(i)\n",
    "            response = f\"\\n\\n### Response:\\n{i['output']}\"\n",
    "            full_text = input + response\n",
    "            self.samples.append(\n",
    "                tokenizer.encode(\n",
    "                    full_text,\n",
    "                )\n",
    "            )\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.samples[idx]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b8f146f",
   "metadata": {},
   "source": [
    "### Data Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b2a749d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[50256]\n"
     ]
    }
   ],
   "source": [
    "import tiktoken\n",
    "\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "\n",
    "print(tokenizer.encode(\"<|endoftext|>\", allowed_special={\"<|endoftext|>\"}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "688ade5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_collate_fn(\n",
    "    batch,\n",
    "    pad_token_id=50256,\n",
    "    ignore_token_id=-100,\n",
    "    allowed_max_length=None,\n",
    "    device=\"cpu\",\n",
    "):\n",
    "    \"\"\"\n",
    "    Custom batch collation function for language model training.\n",
    "    \n",
    "    Pads sequences to the same length, creates input-target pairs for next-token prediction,\n",
    "    and masks padding tokens in targets to ignore them during loss calculation.\n",
    "    \n",
    "    Args:\n",
    "        batch: A batch of data containing multiple encoded token sequences (lists)\n",
    "        pad_token_id: Token ID used for padding, default is 50256 (GPT-2's <|endoftext|> token)\n",
    "        ignore_token_id: Token ID to replace padding tokens in targets, default is -100 (PyTorch's ignore index)\n",
    "        allowed_max_length: Optional maximum length to truncate sequences. If None, uses batch max length\n",
    "        device: Device to move the input tensor to, default is \"cpu\"\n",
    "    \n",
    "    Returns:\n",
    "        tuple: A tuple containing:\n",
    "            - inputs_tensor (torch.Tensor): Input sequences with shape (batch_size, max_length)\n",
    "            - targets_tensor (torch.Tensor): Target sequences with shape (batch_size, max_length).\n",
    "              Padding positions in targets are set to ignore_token_id to be ignored in loss calculation\n",
    "    \"\"\"\n",
    "    batch_max_length = max(len(i) + 1 for i in batch)\n",
    "    input_list, target_list = [], []\n",
    "\n",
    "    for i in batch:\n",
    "        # append the item less than batch_max_length, padding\n",
    "        # create targets\n",
    "        # replace the pad_token_id with ignore_token_id (-100)\n",
    "        new_item = i + [pad_token_id]\n",
    "        padded = new_item + [pad_token_id] * (batch_max_length - len(new_item))\n",
    "\n",
    "        inputs = torch.tensor(padded[:-1]) # remove the last token\n",
    "        targets = torch.tensor(padded[1:])\n",
    "\n",
    "        # targets       = [1 2 3 50256 50256 ...]\n",
    "        # mask          = [False False False True True ...]\n",
    "        # final targets = [ 1 2 50256 -100 -100]\n",
    "        mask = targets == pad_token_id\n",
    "        slice = torch.nonzero(mask).squeeze()\n",
    "        if slice.numel() > 1:\n",
    "            targets[slice[1:]] = ignore_token_id\n",
    "\n",
    "        if allowed_max_length is not None:\n",
    "            inputs = inputs[:allowed_max_length]\n",
    "            targets = targets[:allowed_max_length]\n",
    "\n",
    "        input_list.append(inputs)\n",
    "        target_list.append(targets)\n",
    "\n",
    "    # convert to 2D\n",
    "    inputs_tensor = torch.stack(input_list).to(device)\n",
    "    targets_tensor = torch.stack(target_list)\n",
    "\n",
    "    return inputs_tensor, targets_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c9049c8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2, 3, 4])\n",
      "tensor([    1,     2, 50256,  -100,  -100])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "mask = [False, False, True, True, True]\n",
    "print(torch.nonzero(torch.tensor(mask)).squeeze())\n",
    "\n",
    "slice = torch.nonzero(torch.tensor(mask)).squeeze()\n",
    "targets = torch.tensor([1, 2, 50256, 50256, 50256])\n",
    "targets[slice[1:]] = -100\n",
    "print(targets)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fb90b7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "batch_size = 4\n",
    "torch.manual_seed(123)\n",
    "\n",
    "# Train dataset\n",
    "train_dataset = InstructionDataset(train_data, tokenizer)\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    collate_fn=my_collate_fn,\n",
    "    shuffle=True,\n",
    "    drop_last=True\n",
    ")\n",
    "\n",
    "# Validation dataset\n",
    "val_dataset = InstructionDataset(val_data, tokenizer)\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=batch_size,\n",
    "    collate_fn=my_collate_fn,\n",
    "    shuffle=False,\n",
    "    drop_last=False\n",
    ")\n",
    "\n",
    "# Test dataset\n",
    "test_dataset = InstructionDataset(test_data, tokenizer)\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=batch_size,\n",
    "    collate_fn=my_collate_fn,\n",
    "    shuffle=False,\n",
    "    drop_last=False\n",
    ")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
