import torch
from torch.utils.data import Dataset, DataLoader
import tiktoken

class MyDataset(Dataset):
    def __init__(self, text, tokenizer, max_length, stride):
        super().__init__()

        #北京最有名的山是？香山
        #京最有名的山是？香山【end】
        self.input_ids = []
        self.target_ids = []

        token_ids = tokenizer.encode(text)

        #abcdefghigk
        for i in range(0, len(token_ids) - max_length, stride):
            chunk = token_ids[i:i+max_length]
            target_chunk = token_ids[i+1:i+max_length+1]
            self.input_ids.append(torch.tensor(chunk))
            self.target_ids.append(torch.tensor(target_chunk))
    
    def __len__(self):
        return len(self.input_ids)

    def __getitem__(self, index):
        return self.input_ids[index], self.target_ids[index]
    
def create_dataloader(text, bz=2, max_length=256, stride=128,
                      shuffle=True, drop_last=True, worker_num=0):
    tokenizer = tiktoken.get_encoding("gpt2")
    dataset = MyDataset(text, tokenizer, max_length, stride)
    dataloader = DataLoader(
        dataset,
        batch_size=bz,
        shuffle=shuffle,
        drop_last=drop_last,
        num_workers=worker_num
    )

    return dataloader