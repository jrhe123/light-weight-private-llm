{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fc3cca0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple\n",
      "Collecting google-genai\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/40/f2/97fefdd1ad1f3428321bac819ae7a83ccc59f6439616054736b7819fa56c/google_genai-1.53.0-py3-none-any.whl (262 kB)\n",
      "Requirement already satisfied: anyio<5.0.0,>=4.8.0 in /Users/lichao/miniconda3/envs/LLMs/lib/python3.10/site-packages (from google-genai) (4.12.0)\n",
      "Collecting google-auth<3.0.0,>=2.14.1 (from google-auth[requests]<3.0.0,>=2.14.1->google-genai)\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/6f/d1/385110a9ae86d91cc14c5282c61fe9f4dc41c0b9f7d423c6ad77038c4448/google_auth-2.43.0-py2.py3-none-any.whl (223 kB)\n",
      "Requirement already satisfied: httpx<1.0.0,>=0.28.1 in /Users/lichao/miniconda3/envs/LLMs/lib/python3.10/site-packages (from google-genai) (0.28.1)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.9.0 in /Users/lichao/miniconda3/envs/LLMs/lib/python3.10/site-packages (from google-genai) (2.12.5)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.28.1 in /Users/lichao/miniconda3/envs/LLMs/lib/python3.10/site-packages (from google-genai) (2.32.4)\n",
      "Collecting tenacity<9.2.0,>=8.2.3 (from google-genai)\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/e5/30/643397144bfbfec6f6ef821f36f33e57d35946c44a2352d3c9f0ae847619/tenacity-9.1.2-py3-none-any.whl (28 kB)\n",
      "Collecting websockets<15.1.0,>=13.0.0 (from google-genai)\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/d5/4f/b462242432d93ea45f297b6179c7333dd0402b855a912a04e7fc61c0d71f/websockets-15.0.1-cp310-cp310-macosx_11_0_arm64.whl (173 kB)\n",
      "Requirement already satisfied: typing-extensions<5.0.0,>=4.11.0 in /Users/lichao/miniconda3/envs/LLMs/lib/python3.10/site-packages (from google-genai) (4.14.1)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /Users/lichao/miniconda3/envs/LLMs/lib/python3.10/site-packages (from anyio<5.0.0,>=4.8.0->google-genai) (1.3.0)\n",
      "Requirement already satisfied: idna>=2.8 in /Users/lichao/miniconda3/envs/LLMs/lib/python3.10/site-packages (from anyio<5.0.0,>=4.8.0->google-genai) (3.10)\n",
      "Collecting cachetools<7.0,>=2.0.0 (from google-auth<3.0.0,>=2.14.1->google-auth[requests]<3.0.0,>=2.14.1->google-genai)\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/e6/46/eb6eca305c77a4489affe1c5d8f4cae82f285d9addd8de4ec084a7184221/cachetools-6.2.2-py3-none-any.whl (11 kB)\n",
      "Collecting pyasn1-modules>=0.2.1 (from google-auth<3.0.0,>=2.14.1->google-auth[requests]<3.0.0,>=2.14.1->google-genai)\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/47/8d/d529b5d697919ba8c11ad626e835d4039be708a35b0d22de83a269a6682c/pyasn1_modules-0.4.2-py3-none-any.whl (181 kB)\n",
      "Collecting rsa<5,>=3.1.4 (from google-auth<3.0.0,>=2.14.1->google-auth[requests]<3.0.0,>=2.14.1->google-genai)\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/64/8d/0133e4eb4beed9e425d9a98ed6e081a55d195481b7632472be1af08d2f6b/rsa-4.9.1-py3-none-any.whl (34 kB)\n",
      "Requirement already satisfied: certifi in /Users/lichao/miniconda3/envs/LLMs/lib/python3.10/site-packages (from httpx<1.0.0,>=0.28.1->google-genai) (2025.8.3)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/lichao/miniconda3/envs/LLMs/lib/python3.10/site-packages (from httpx<1.0.0,>=0.28.1->google-genai) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in /Users/lichao/miniconda3/envs/LLMs/lib/python3.10/site-packages (from httpcore==1.*->httpx<1.0.0,>=0.28.1->google-genai) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Users/lichao/miniconda3/envs/LLMs/lib/python3.10/site-packages (from pydantic<3.0.0,>=2.9.0->google-genai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.5 in /Users/lichao/miniconda3/envs/LLMs/lib/python3.10/site-packages (from pydantic<3.0.0,>=2.9.0->google-genai) (2.41.5)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in /Users/lichao/miniconda3/envs/LLMs/lib/python3.10/site-packages (from pydantic<3.0.0,>=2.9.0->google-genai) (0.4.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /Users/lichao/miniconda3/envs/LLMs/lib/python3.10/site-packages (from requests<3.0.0,>=2.28.1->google-genai) (3.4.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/lichao/miniconda3/envs/LLMs/lib/python3.10/site-packages (from requests<3.0.0,>=2.28.1->google-genai) (2.5.0)\n",
      "Collecting pyasn1>=0.1.3 (from rsa<5,>=3.1.4->google-auth<3.0.0,>=2.14.1->google-auth[requests]<3.0.0,>=2.14.1->google-genai)\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/c8/f1/d6a797abb14f6283c0ddff96bbdd46937f64122b8c925cab503dd37f8214/pyasn1-0.6.1-py3-none-any.whl (83 kB)\n",
      "Installing collected packages: websockets, tenacity, pyasn1, cachetools, rsa, pyasn1-modules, google-auth, google-genai\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m8/8\u001b[0m [google-genai][0m [google-genai]s]\n",
      "\u001b[1A\u001b[2KSuccessfully installed cachetools-6.2.2 google-auth-2.43.0 google-genai-1.53.0 pyasn1-0.6.1 pyasn1-modules-0.4.2 rsa-4.9.1 tenacity-9.1.2 websockets-15.0.1\n"
     ]
    }
   ],
   "source": [
    "!pip install google-genai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb678056",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import json\n",
    "from pydantic import BaseModel, Field\n",
    "from google import genai\n",
    "from google.genai import types\n",
    "\n",
    "# ---------------- é…ç½®éƒ¨åˆ† ----------------\n",
    "\n",
    "# è¯·æ›¿æ¢ä¸ºä½ çš„ API Keyï¼Œæˆ–è€…è®¾ç½®ç¯å¢ƒå˜é‡ GEMINI_API_KEY\n",
    "# https://aistudio.google.com/api-keys\n",
    "API_KEY = \"ä½ è‡ªå·±çš„API Key\"\n",
    "\n",
    "# è®¾ç½®ç›®æ ‡é¢˜ç›®æ•°é‡\n",
    "TOTAL_QUESTIONS = 1000\n",
    "# æ¯æ¬¡è¯·æ±‚è·å–çš„é¢˜ç›®æ•° (å»ºè®® 20-50 ä¹‹é—´ï¼Œé¿å…è¶…å‡ºå•æ¬¡è¾“å‡º Token é™åˆ¶)\n",
    "BATCH_SIZE = 50 \n",
    "# è¾“å‡ºæ–‡ä»¶å\n",
    "OUTPUT_FILE = \"math_problems_1000.json\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e7935099",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "å¼€å§‹è·å– 1000 é“çº¯æ•°å­¦é¢˜ (æ— ç­”æ¡ˆ)...\n",
      "æ­£åœ¨è¯·æ±‚... (å½“å‰è¿›åº¦: 0/1000)\n",
      "æ­£åœ¨è¯·æ±‚... (å½“å‰è¿›åº¦: 50/1000)\n",
      "æ­£åœ¨è¯·æ±‚... (å½“å‰è¿›åº¦: 100/1000)\n",
      "æ­£åœ¨è¯·æ±‚... (å½“å‰è¿›åº¦: 150/1000)\n",
      "æ­£åœ¨è¯·æ±‚... (å½“å‰è¿›åº¦: 200/1000)\n",
      "æ­£åœ¨è¯·æ±‚... (å½“å‰è¿›åº¦: 250/1000)\n",
      "æ­£åœ¨è¯·æ±‚... (å½“å‰è¿›åº¦: 300/1000)\n",
      "æ­£åœ¨è¯·æ±‚... (å½“å‰è¿›åº¦: 350/1000)\n",
      "æ­£åœ¨è¯·æ±‚... (å½“å‰è¿›åº¦: 400/1000)\n",
      "æ­£åœ¨è¯·æ±‚... (å½“å‰è¿›åº¦: 450/1000)\n",
      "æ­£åœ¨è¯·æ±‚... (å½“å‰è¿›åº¦: 500/1000)\n",
      "æ­£åœ¨è¯·æ±‚... (å½“å‰è¿›åº¦: 549/1000)\n",
      "æ­£åœ¨è¯·æ±‚... (å½“å‰è¿›åº¦: 599/1000)\n",
      "æ­£åœ¨è¯·æ±‚... (å½“å‰è¿›åº¦: 649/1000)\n",
      "æ­£åœ¨è¯·æ±‚... (å½“å‰è¿›åº¦: 699/1000)\n",
      "æ­£åœ¨è¯·æ±‚... (å½“å‰è¿›åº¦: 749/1000)\n",
      "æ­£åœ¨è¯·æ±‚... (å½“å‰è¿›åº¦: 798/1000)\n",
      "æ­£åœ¨è¯·æ±‚... (å½“å‰è¿›åº¦: 848/1000)\n",
      "æ­£åœ¨è¯·æ±‚... (å½“å‰è¿›åº¦: 899/1000)\n",
      "æ­£åœ¨è¯·æ±‚... (å½“å‰è¿›åº¦: 948/1000)\n",
      "æ­£åœ¨è¯·æ±‚... (å½“å‰è¿›åº¦: 999/1000)\n",
      "å®Œæˆï¼å·²ä¿å­˜åˆ° math_problems_1000.json\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ---------------- 1. å®šä¹‰æå…¶ç®€å•çš„â€œæ¨¡å…·â€ ----------------\n",
    "# å‘Šè¯‰ Geminiï¼šæˆ‘åªè¦è¿™ä¸¤ä¸ªå­—æ®µï¼Œåˆ«çš„éƒ½ä¸è¦\n",
    "class SimpleQuestion(BaseModel):\n",
    "    grade: str = Field(description=\"å¹´çº§ï¼Œå¦‚ '4å¹´çº§'\")\n",
    "    content: str = Field(description=\"æ•°å­¦é¢˜ç›®çš„å…·ä½“å†…å®¹ï¼Œä¸åŒ…å«ç­”æ¡ˆ\")\n",
    "\n",
    "# ---------------- ä¸»ç¨‹åº ----------------\n",
    "def main():\n",
    "    client = genai.Client(api_key=API_KEY)\n",
    "    \n",
    "    all_data = [] # ç”¨æ¥å­˜æ‰€æœ‰çš„é¢˜ç›®\n",
    "    \n",
    "    print(f\"å¼€å§‹è·å– {TOTAL_QUESTIONS} é“çº¯æ•°å­¦é¢˜ (æ— ç­”æ¡ˆ)...\")\n",
    "\n",
    "    while len(all_data) < TOTAL_QUESTIONS:\n",
    "        # è®¡ç®—è¿˜è¦å¤šå°‘é“\n",
    "        needed = TOTAL_QUESTIONS - len(all_data)\n",
    "        current_batch_size = min(BATCH_SIZE, needed)\n",
    "        \n",
    "        print(f\"æ­£åœ¨è¯·æ±‚... (å½“å‰è¿›åº¦: {len(all_data)}/{TOTAL_QUESTIONS})\")\n",
    "\n",
    "        # æç¤ºè¯ï¼šæ˜ç¡®å‘Šè¯‰å®ƒä¸è¦ç­”æ¡ˆ\n",
    "        prompt = (\n",
    "            f\"è¯·ç»™æˆ‘ {current_batch_size} é“å°å­¦ 4-6 å¹´çº§çš„æ•°å­¦é¢˜ã€‚\"\n",
    "            \"è¦æ±‚ï¼š\\n\"\n",
    "            \"1. åªè¦é¢˜ç›®ï¼Œç»å¯¹ä¸è¦ç­”æ¡ˆï¼Œä¹Ÿä¸è¦é€‰é¡¹ã€‚\\n\"\n",
    "            \"2. é¢˜ç›®ç±»å‹åŒ…å«è®¡ç®—ã€åº”ç”¨é¢˜ã€å‡ ä½•ã€‚\\n\"\n",
    "            \"3. é¢˜ç›®æè¿°è¦æ¸…æ™°ã€‚\"\n",
    "        )\n",
    "\n",
    "        try:\n",
    "            response = client.models.generate_content(\n",
    "                model=\"gemini-2.0-flash\", # å»ºè®®ç”¨ Flashï¼Œé€Ÿåº¦å¿«ä¸”ä¾¿å®œï¼Œè¶³å¤Ÿç”Ÿæˆé¢˜ç›®\n",
    "                contents=prompt,\n",
    "                config=types.GenerateContentConfig(\n",
    "                    response_mime_type=\"application/json\",\n",
    "                    response_schema=list[SimpleQuestion], # å…³é”®ï¼šå¥—ç”¨ä¸Šé¢çš„ç®€å•æ¨¡å…·\n",
    "                    temperature=0.8,\n",
    "                ),\n",
    "            )\n",
    "\n",
    "            if response.parsed:\n",
    "                # æŠŠè¿™ä¸€æ‰¹é¢˜ç›®åŠ åˆ°æ€»åˆ—è¡¨é‡Œ\n",
    "                for item in response.parsed:\n",
    "                    all_data.append(item.model_dump())\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"å‡ºé”™é‡è¯•: {e}\")\n",
    "            time.sleep(2)\n",
    "            continue\n",
    "            \n",
    "        time.sleep(1) # ç¨å¾®æ­‡ä¸€ä¸‹ï¼Œé˜²æ­¢è¯·æ±‚å¤ªå¿«\n",
    "\n",
    "    # ---------------- ä¿å­˜æ–‡ä»¶ ----------------\n",
    "    # æ„é€ æˆä½ æƒ³è¦çš„æ ¼å¼ { \"questions\": [ ... ] }\n",
    "    final_json = {\n",
    "        \"questions\": all_data\n",
    "    }\n",
    "\n",
    "    with open(OUTPUT_FILE, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(final_json, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "    print(f\"å®Œæˆï¼å·²ä¿å­˜åˆ° {OUTPUT_FILE}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c5e29d58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "æ­£åœ¨è¯»å– math_dataset_with_answers.jsonl ...\n",
      "ç»„è£…å®Œæˆï¼Œå…± 1012 æ¡æ•°æ®ã€‚\n",
      "æ­£åœ¨å‘é€ç»™ gemini-2.5-pro è¿›è¡Œæ·±åº¦æ£€æŸ¥...\n",
      "è¿™å¯èƒ½éœ€è¦ 1-2 åˆ†é’Ÿï¼Œè¯·è€å¿ƒç­‰å¾…...\n",
      "âŒ è¯·æ±‚å‘ç”Ÿé”™è¯¯: 503 UNAVAILABLE. {'error': {'code': 503, 'message': 'The model is overloaded. Please try again later.', 'status': 'UNAVAILABLE'}}\n"
     ]
    }
   ],
   "source": [
    "INPUT_FILE = \"math_dataset_with_answers.jsonl\"\n",
    "OUTPUT_FILE = \"incorrect_analysis.json\"\n",
    "\n",
    "# ä½¿ç”¨é€»è¾‘èƒ½åŠ›æœ€å¼ºçš„ Pro ç‰ˆæœ¬\n",
    "MODEL_NAME = \"gemini-2.5-pro\" \n",
    "\n",
    "# ---------------- 1. å®šä¹‰æ–°çš„è¾“å‡ºç»“æ„ ----------------\n",
    "\n",
    "# å®šä¹‰å•ä¸ªé”™è¯¯é¡¹ï¼šåŒ…å« ID å’Œ åŸå› \n",
    "class IncorrectItem(BaseModel):\n",
    "    id: int = Field(description=\"é¢˜ç›®å¯¹åº”çš„ ID ç¼–å·\")\n",
    "    reason: str = Field(description=\"ç®€çŸ­è§£é‡Šä¸ºä»€ä¹ˆè¿™é“é¢˜æ˜¯é”™çš„ï¼ˆä¾‹å¦‚ï¼š'è®¡ç®—é”™è¯¯ï¼Œ3+5åº”ä¸º8' æˆ– 'é€»è¾‘æ¨å¯¼æœ‰è¯¯'ï¼‰\")\n",
    "\n",
    "# å®šä¹‰æœ€ç»ˆè¿”å›çš„åˆ—è¡¨ç»“æ„\n",
    "class ReviewResult(BaseModel):\n",
    "    incorrect_items: list[IncorrectItem]\n",
    "\n",
    "# ---------------- ä¸»ç¨‹åº ----------------\n",
    "def main():\n",
    "    client = genai.Client(api_key=API_KEY)\n",
    "\n",
    "    # 1. è¯»å–å¹¶ç»„è£…æ•°æ®\n",
    "    if not os.path.exists(INPUT_FILE):\n",
    "        print(f\"æ‰¾ä¸åˆ°æ–‡ä»¶: {INPUT_FILE}\")\n",
    "        return\n",
    "\n",
    "    print(f\"æ­£åœ¨è¯»å– {INPUT_FILE} ...\")\n",
    "    \n",
    "    full_content_for_prompt = \"\"\n",
    "    total_count = 0\n",
    "\n",
    "    with open(INPUT_FILE, \"r\", encoding=\"utf-8\") as f:\n",
    "        for index, line in enumerate(f):\n",
    "            line = line.strip()\n",
    "            if not line: continue\n",
    "            \n",
    "            try:\n",
    "                item = json.loads(line)\n",
    "                # ç»„è£…æ–‡æœ¬ï¼Œæ˜ç¡®æ ‡å‡º ID\n",
    "                record_str = (\n",
    "                    f\"ID: {index}\\n\"\n",
    "                    f\"Question: {item.get('instruction')}\\n\"\n",
    "                    f\"Thinking: {item.get('thinking')}\\n\"\n",
    "                    f\"Answer: {item.get('output')}\\n\"\n",
    "                    f\"-----------------------------\\n\"\n",
    "                )\n",
    "                full_content_for_prompt += record_str\n",
    "                total_count += 1\n",
    "            except:\n",
    "                continue\n",
    "\n",
    "    print(f\"ç»„è£…å®Œæˆï¼Œå…± {total_count} æ¡æ•°æ®ã€‚\")\n",
    "    print(f\"æ­£åœ¨å‘é€ç»™ {MODEL_NAME} è¿›è¡Œæ·±åº¦æ£€æŸ¥...\")\n",
    "    print(\"è¿™å¯èƒ½éœ€è¦ 1-2 åˆ†é’Ÿï¼Œè¯·è€å¿ƒç­‰å¾…...\")\n",
    "\n",
    "    # 2. æ„é€ æç¤ºè¯\n",
    "    prompt = (\n",
    "        \"ä½ æ˜¯ä¸€ä½èµ„æ·±æ•°å­¦è€å¸ˆã€‚è¯·ä»”ç»†æ£€æŸ¥ä»¥ä¸‹æ‰€æœ‰æ•°å­¦é¢˜çš„ã€æ¨ç†è¿‡ç¨‹ã€‘å’Œã€æœ€ç»ˆç­”æ¡ˆã€‘ã€‚\\n\"\n",
    "        \"å¦‚æœå‘ç°ä»»ä½•é”™è¯¯ï¼ˆè®¡ç®—é”™è¯¯ã€é€»è¾‘è°¬è¯¯ã€æˆ–è€…ç­”æ¡ˆé”™è¯¯ï¼‰ï¼Œè¯·å°†å…¶è®°å½•ä¸‹æ¥ã€‚\\n\"\n",
    "        \"\\n\"\n",
    "        \"ä»»åŠ¡è¦æ±‚ï¼š\\n\"\n",
    "        \"1. å¦‚æœé¢˜ç›®å®Œå…¨æ­£ç¡®ï¼Œå¿½ç•¥å®ƒã€‚\\n\"\n",
    "        \"2. å¦‚æœæœ‰é”™ï¼Œè¯·è®°å½•å…¶ IDï¼Œå¹¶ç”¨ç®€çŸ­çš„ä¸­æ–‡è¯´æ˜é”™è¯¯åŸå› ã€‚\\n\"\n",
    "        \"3. ä¸¥æ ¼æŒ‰ç…§å®šä¹‰çš„ JSON æ ¼å¼è¿”å›ç»“æœã€‚\\n\"\n",
    "        \"\\n\"\n",
    "        \"ä»¥ä¸‹æ˜¯å¾…æ£€æŸ¥çš„é¢˜ç›®åˆ—è¡¨ï¼š\\n\"\n",
    "        f\"{full_content_for_prompt}\"\n",
    "    )\n",
    "\n",
    "    try:\n",
    "        # 3. è°ƒç”¨ API\n",
    "        response = client.models.generate_content(\n",
    "            model=MODEL_NAME,\n",
    "            contents=prompt,\n",
    "            config=types.GenerateContentConfig(\n",
    "                response_mime_type=\"application/json\",\n",
    "                response_schema=ReviewResult, # å…³é”®ï¼šä½¿ç”¨æ–°çš„ç»“æ„\n",
    "                temperature=0.1, # ä½æ¸©åº¦ä¿è¯ä¸¥è°¨\n",
    "            ),\n",
    "        )\n",
    "\n",
    "        # 4. è§£æç»“æœ\n",
    "        if response.parsed:\n",
    "            errors = response.parsed.incorrect_items\n",
    "            \n",
    "            # æŒ‰ ID æ’åºï¼Œæ–¹ä¾¿æŸ¥çœ‹\n",
    "            errors.sort(key=lambda x: x.id)\n",
    "            \n",
    "            print(\"-\" * 50)\n",
    "            if not errors:\n",
    "                print(\"ğŸ‰ å¤ªæ£’äº†ï¼Gemini æ²¡æœ‰å‘ç°ä»»ä½•é”™è¯¯ï¼Œå…¨å¯¹ï¼\")\n",
    "            else:\n",
    "                print(f\"æ£€æŸ¥å®Œæˆï¼å…±å‘ç° {len(errors)} ä¸ªé”™è¯¯ï¼š\\n\")\n",
    "                \n",
    "                # æ‰“å°åˆ°æ§åˆ¶å°é¢„è§ˆ\n",
    "                for item in errors[:10]: # åªæ‰“å°å‰10ä¸ªé¿å…åˆ·å±\n",
    "                    print(f\"[ID: {item.id}] âŒ {item.reason}\")\n",
    "                \n",
    "                if len(errors) > 10:\n",
    "                    print(f\"... è¿˜æœ‰ {len(errors)-10} ä¸ªé”™è¯¯æœªæ˜¾ç¤ºã€‚\")\n",
    "\n",
    "                # è½¬æ¢ä¸ºå­—å…¸åˆ—è¡¨ä»¥ä¾¿ä¿å­˜\n",
    "                save_data = [item.model_dump() for item in errors]\n",
    "\n",
    "                # ä¿å­˜åˆ°æ–‡ä»¶\n",
    "                with open(OUTPUT_FILE, \"w\", encoding=\"utf-8\") as f:\n",
    "                    json.dump(save_data, f, ensure_ascii=False, indent=2)\n",
    "                \n",
    "                print(f\"\\nå®Œæ•´é”™è¯¯æŠ¥å‘Šå·²ä¿å­˜è‡³: {OUTPUT_FILE}\")\n",
    "            \n",
    "        else:\n",
    "            print(\"API è¿”å›å†…å®¹æ— æ³•è§£æã€‚\")\n",
    "            print(\"åŸå§‹è¿”å›:\", response.text)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ è¯·æ±‚å‘ç”Ÿé”™è¯¯: {e}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7d7d3b24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "æ­£åœ¨åˆ—å‡ºå¯ç”¨æ¨¡å‹...\n",
      "- models/embedding-gecko-001\n",
      "- models/gemini-2.5-flash\n",
      "- models/gemini-2.5-pro\n",
      "- models/gemini-2.0-flash-exp\n",
      "- models/gemini-2.0-flash\n",
      "- models/gemini-2.0-flash-001\n",
      "- models/gemini-2.0-flash-exp-image-generation\n",
      "- models/gemini-2.0-flash-lite-001\n",
      "- models/gemini-2.0-flash-lite\n",
      "- models/gemini-2.0-flash-lite-preview-02-05\n",
      "- models/gemini-2.0-flash-lite-preview\n",
      "- models/gemini-2.0-pro-exp\n",
      "- models/gemini-2.0-pro-exp-02-05\n",
      "- models/gemini-exp-1206\n",
      "- models/gemini-2.5-flash-preview-tts\n",
      "- models/gemini-2.5-pro-preview-tts\n",
      "- models/gemma-3-1b-it\n",
      "- models/gemma-3-4b-it\n",
      "- models/gemma-3-12b-it\n",
      "- models/gemma-3-27b-it\n",
      "- models/gemma-3n-e4b-it\n",
      "- models/gemma-3n-e2b-it\n",
      "- models/gemini-flash-latest\n",
      "- models/gemini-flash-lite-latest\n",
      "- models/gemini-pro-latest\n",
      "- models/gemini-2.5-flash-lite\n",
      "- models/gemini-2.5-flash-image-preview\n",
      "- models/gemini-2.5-flash-image\n",
      "- models/gemini-2.5-flash-preview-09-2025\n",
      "- models/gemini-2.5-flash-lite-preview-09-2025\n",
      "- models/gemini-3-pro-preview\n",
      "- models/gemini-3-pro-image-preview\n",
      "- models/nano-banana-pro-preview\n",
      "- models/gemini-robotics-er-1.5-preview\n",
      "- models/gemini-2.5-computer-use-preview-10-2025\n",
      "- models/embedding-001\n",
      "- models/text-embedding-004\n",
      "- models/gemini-embedding-exp-03-07\n",
      "- models/gemini-embedding-exp\n",
      "- models/gemini-embedding-001\n",
      "- models/aqa\n",
      "- models/imagen-4.0-generate-preview-06-06\n",
      "- models/imagen-4.0-ultra-generate-preview-06-06\n",
      "- models/imagen-4.0-generate-001\n",
      "- models/imagen-4.0-ultra-generate-001\n",
      "- models/imagen-4.0-fast-generate-001\n",
      "- models/veo-2.0-generate-001\n",
      "- models/veo-3.0-generate-001\n",
      "- models/veo-3.0-fast-generate-001\n",
      "- models/veo-3.1-generate-preview\n",
      "- models/veo-3.1-fast-generate-preview\n",
      "- models/gemini-2.0-flash-live-001\n",
      "- models/gemini-live-2.5-flash-preview\n",
      "- models/gemini-2.5-flash-live-preview\n",
      "- models/gemini-2.5-flash-native-audio-latest\n",
      "- models/gemini-2.5-flash-native-audio-preview-09-2025\n"
     ]
    }
   ],
   "source": [
    "client = genai.Client(api_key=API_KEY)\n",
    "\n",
    "print(\"æ­£åœ¨åˆ—å‡ºå¯ç”¨æ¨¡å‹...\")\n",
    "try:\n",
    "    # æ–°ç‰ˆ SDK çš„ list æ–¹æ³•è¿”å›çš„æ˜¯ä¸€ä¸ªè¿­ä»£å™¨\n",
    "    for model in client.models.list():\n",
    "        # ç›´æ¥æ‰“å° model.nameï¼Œä¸è¿›è¡Œå±æ€§è¿‡æ»¤ï¼Œé˜²æ­¢æŠ¥é”™\n",
    "        print(f\"- {model.name}\")\n",
    "        # å¦‚æœä½ æƒ³çœ‹å®ƒçš„æ‰€æœ‰å±æ€§ï¼Œå¯ä»¥ç”¨ print(model.model_dump())\n",
    "except Exception as e:\n",
    "    print(f\"æŸ¥è¯¢å‡ºé”™: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LLMs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
